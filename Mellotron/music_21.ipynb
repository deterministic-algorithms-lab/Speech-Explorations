{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music-21.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1JVX9ZxKjVgRlylBmS+oG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deterministic-algorithms-lab/Speech-Explorations/blob/master/Mellotron/music_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8-qxTNVeYi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install music21"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S2OeOzWf578",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NVIDIA/mellotron"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_quEo-zlLGi",
        "colab_type": "text"
      },
      "source": [
        "Music 21 can parse music files in various formats. XML format is one of them. See sample in ```mellotron/data/*.musicxml```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ-Ft79jgyP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import music21 as m21\n",
        "s = m21.corpus.parse('bach/bwv65.2.xml')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05ulFr6NiOAE",
        "colab_type": "text"
      },
      "source": [
        "The [flats](https://en.wikipedia.org/wiki/Flat_(music)) of the music. The [SATB](https://en.wikipedia.org/wiki/SATB) are four kinds of musical voices, in a choir.. varying from high pitched female(S=Soprano) to low pitched male(B=Bass)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMtaNAEUhzl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(s.parts)):\n",
        "    flat_part = s.parts[i].flat\n",
        "    print(flat_part.partName)\n",
        "    print(\"SATB:............ \", flat_part)\n",
        "    for k in range(len(flat_part.notesAndRests)):\n",
        "        event = flat_part.notesAndRests[k]\n",
        "        print(event)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igrNFiZsmSC4",
        "colab_type": "text"
      },
      "source": [
        "Getting Data from a note. 'bpm' is the number of beats you want per minute. See the demo [here](https://learningmusic.ableton.com/make-beats/beat-and-tempo.html). A \"[Note](https://en.wikipedia.org/wiki/Musical_note)\" is a symbol denoting a distinct musical sound."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "664AN4r-mWFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bpm = 60 \n",
        "beat_length_seconds = 60/bpm\n",
        "for i in range(len(s.parts)):\n",
        "    flat_part = s.parts[i].flat\n",
        "    print(\"SATB:............ \", flat_part)\n",
        "    for k in range(len(flat_part.notesAndRests)):\n",
        "        event = flat_part.notesAndRests[k]\n",
        "        print(event)\n",
        "        if isinstance(event, m21.note.Note):\n",
        "            freq = event.pitch.frequency\n",
        "            token = event.lyrics[0].text if len(event.lyrics) > 0 else ' '\n",
        "            start_time = event.offset * beat_length_seconds\n",
        "            end_time = start_time + event.duration.quarterLength * beat_length_seconds\n",
        "            event = [token, freq, start_time, end_time]\n",
        "            print(\"Note : \", token, freq, start_time, end_time)\n",
        "        elif isinstance(event, m21.note.Rest):\n",
        "            freq = 0\n",
        "            token = ' '\n",
        "            start_time = event.offset * beat_length_seconds\n",
        "            end_time = start_time + event.duration.quarterLength * beat_length_seconds\n",
        "            event = [token, freq, start_time, end_time]\n",
        "            print(\"Rest : \", token, freq, start_time, end_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhCq5jjE0rKD",
        "colab_type": "text"
      },
      "source": [
        "* All words appear in soprano, so that is the voice being used. \n",
        "* The duration of a note is relative to the speed of beats(bpm). \n",
        "* The ```event.duration.quarterLength``` is the number of quarterLengths of a beat(i.e., if a beat takes 60 seconds to play, then it is the number of 15 seconds for which the event should continue happening), that the even(note/rest) must last for. See [here](http://neilhawes.com/sstheory/theory12.htm) for more.\n",
        "\n"
      ]
    }
  ]
}