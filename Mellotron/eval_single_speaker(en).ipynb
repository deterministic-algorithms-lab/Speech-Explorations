{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "eval-single_speaker(en).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deterministic-algorithms-lab/Speech-Explorations/blob/master/Mellotron/eval_single_speaker(en).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-QJimiltoud"
      },
      "source": [
        "!mkdir weights\n",
        "%cd weights\n",
        "!gdown https://drive.google.com/uc?id=1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF         #For WaveGlow\n",
        "!gdown https://drive.google.com/uc?id=1UwDARlUl8JvB2xSuyMFHFsIWELVpgQD4         #For LJS mellotron model\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYJzIBeQsA5p"
      },
      "source": [
        "!git clone https://github.com/deterministic-algorithms-lab/Speech-Explorations\n",
        "%cd Speech-Explorations/Mellotron/mellotron/\n",
        "!git clone https://github.com/NVIDIA/waveglow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7OHHWZpwOly"
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install soundfile\n",
        "!pip install git+git://github.com/libindic/indic-trans.git\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSNRf-b0wuss"
      },
      "source": [
        "%tensorflow_version 1.12.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xa1WiFOqL5n"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "import sys\n",
        "sys.path.append('waveglow/')\n",
        "\n",
        "from itertools import cycle\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.io.wavfile import write\n",
        "import pandas as pd4\n",
        "import librosa\n",
        "import torch\n",
        "\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2, load_model\n",
        "from waveglow.denoiser import Denoiser\n",
        "from layers import TacotronSTFT\n",
        "from data_utils import TextMelLoader, TextMelCollate\n",
        "from text import cmudict, text_to_sequence\n",
        "from mellotron_utils import get_data_from_musicxml"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "412XeGEiqL51"
      },
      "source": [
        "def panner(signal, angle):\n",
        "    angle = np.radians(angle)\n",
        "    left = np.sqrt(2)/2.0 * (np.cos(angle) - np.sin(angle)) * signal\n",
        "    right = np.sqrt(2)/2.0 * (np.cos(angle) + np.sin(angle)) * signal\n",
        "    return np.dstack((left, right))[0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOCwvzaEqL5_"
      },
      "source": [
        "def plot_mel_f0_alignment(mel_source, mel_outputs_postnet, f0s, alignments, figsize=(16, 16)):\n",
        "    offset = (mel_source is None)\n",
        "    fig, axes = plt.subplots(4-offset, 1, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    if mel_source is not None:\n",
        "        axes[0].imshow(mel_source, aspect='auto', origin='bottom', interpolation='none')\n",
        "    axes[1-offset].imshow(mel_outputs_postnet, aspect='auto', origin='bottom', interpolation='none')\n",
        "    axes[2-offset].scatter(range(len(f0s)), f0s, alpha=0.5, color='red', marker='.', s=1)\n",
        "    axes[2-offset].set_xlim(0, len(f0s))\n",
        "    axes[3-offset].imshow(alignments, aspect='auto', origin='bottom', interpolation='none')\n",
        "    if mel_source is not None:\n",
        "        axes[0].set_title(\"Source Mel\")\n",
        "    axes[1-offset].set_title(\"Predicted Mel\")\n",
        "    axes[2-offset].set_title(\"Source pitch contour\")\n",
        "    axes[3-offset].set_title(\"Source rhythm\")\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ-rPTcUqL6H"
      },
      "source": [
        "def load_mel(path):\n",
        "    audio, sampling_rate = librosa.core.load(path, sr=hparams.sampling_rate)\n",
        "    audio = torch.from_numpy(audio)\n",
        "    if sampling_rate != hparams.sampling_rate:\n",
        "        raise ValueError(\"{} SR doesn't match target {} SR\".format(\n",
        "            sampling_rate, stft.sampling_rate))\n",
        "    audio_norm = audio.unsqueeze(0)\n",
        "    audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
        "    melspec = stft.mel_spectrogram(audio_norm)\n",
        "    melspec = melspec.cuda()\n",
        "    return melspec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMz_9eKmqL6O"
      },
      "source": [
        "hparams = create_hparams()\n",
        "hparams.text_cleaners = ['english_cleaners']\n",
        "hparams.n_speakers = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ehZWJ9FqL6V"
      },
      "source": [
        "stft = TacotronSTFT(hparams.filter_length, hparams.hop_length, hparams.win_length,\n",
        "                    hparams.n_mel_channels, hparams.sampling_rate, hparams.mel_fmin,\n",
        "                    hparams.mel_fmax)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l25eOsj5qL6e"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBn7pSErqL6e"
      },
      "source": [
        "checkpoint_path = \"/content/weights/mellotron_ljs.pt\"\n",
        "mellotron = load_model(hparams).cuda().eval()\n",
        "mellotron.load_state_dict(torch.load(checkpoint_path)['state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Ob5IzGgrqL6l"
      },
      "source": [
        "waveglow_path = '/content/weights/waveglow_256channels_universal_v5.pt'\n",
        "waveglow = torch.load(waveglow_path)['model'].cuda().eval()\n",
        "denoiser = Denoiser(waveglow).cuda().eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibn09DP0qL6r"
      },
      "source": [
        "## Setup dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKxiErpW7KBt"
      },
      "source": [
        "#To add language and speaker number\n",
        "#!sed 's/$/|0/' ../sample_data/trans_audio.txt > ../sample_data/train_file1.txt\n",
        "#!sed 's/$/|0/' ../sample_data/train_file1.txt > ../sample_data/train_file2.txt "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSoMUyvj9Smn"
      },
      "source": [
        "#To change path\n",
        "#!sed 's+drive/My Drive/sample_data/+Speech-Explorations/Mellotron/sample_data/+' ../sample_data/trans_audio.txt > ../sample_data/trans_audio1.txt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHBm8zQ9c4n2"
      },
      "source": [
        "!echo \"../sample_data/LJ037-0171.wav|The examination and testimony of the experts enabled the Commission to conclude that five shots may have been fired,|0|0\" > ../sample_data/single_speaker.txt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EK78XSIRqL6u"
      },
      "source": [
        "arpabet_dict = cmudict.CMUDict('data/cmu_dictionary')\n",
        "audio_paths = '../sample_data/single_speaker.txt'\n",
        "dataloader = TextMelLoader(audio_paths, hparams)\n",
        "datacollate = TextMelCollate(1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHgUYhHjqL60"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgmkpY3iqL60"
      },
      "source": [
        "file_idx=0\n",
        "audio_path, text, sid, lang = dataloader.audiopaths_and_text[file_idx]\n",
        "mel = load_mel(audio_path)\n",
        "\n",
        "#text = 'My name is Martha White.'\n",
        "text_encoded = torch.LongTensor(text_to_sequence(text, hparams.text_cleaners, arpabet_dict))[None, :].cuda()\n",
        "pitch_contour = dataloader[file_idx][3][None].cuda()\n",
        "print(audio_path, text)\n",
        "\n",
        "x, y = mellotron.parse_batch(datacollate([dataloader[file_idx]]))\n",
        "with torch.no_grad():\n",
        "    # get rhythm (alignment map) using tacotron 2\n",
        "    mel_outputs, mel_outputs_postnet, gate_outputs, rhythm = mellotron.forward(x)\n",
        "    rhythm = rhythm.permute(1, 0, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SexR6OV6prB1"
      },
      "source": [
        "#Run to sharpen alignment plots\n",
        "'''\n",
        "sm = torch.nn.Softmax(dim=2)\n",
        "print(rhythm.shape)\n",
        "temperature=0.1\n",
        "rhythm = sm(rhythm/temperature)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4wAdgX1mlaU"
      },
      "source": [
        "ipd.Audio(audio_path, rate=hparams.sampling_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H7aU9s6qL7J"
      },
      "source": [
        "# Style Transfer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHUMqgU3d-Wt"
      },
      "source": [
        "### Rhythm and Pitch Contour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF1QY4Au-M0n"
      },
      "source": [
        "* Changing text and providing alignments as ```rhythm[:,:,:text_encoded.shape[1]]``` doesn't work here.\n",
        "\n",
        "* Can replace mel by a number too. \n",
        "\n",
        "* Need to try what happens when slight shifts are made in original ```rhythm```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "S26TYF9WqL7N"
      },
      "source": [
        "speaker_id = torch.LongTensor([0]).cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "    print(text_encoded.shape, mel.shape, pitch_contour.shape, rhythm.shape)\n",
        "    mel_outputs, mel_outputs_postnet, gate_outputs, alignments = mellotron.inference_noattention(\n",
        "        (text_encoded, mel, speaker_id, pitch_contour, rhythm[:,:,:))\n",
        "\n",
        "plot_mel_f0_alignment(x[2].data.cpu().numpy()[0],\n",
        "                      mel_outputs_postnet.data.cpu().numpy()[0],\n",
        "                      pitch_contour.data.cpu().numpy()[0, 0],\n",
        "                      rhythm[:100,:,:text_encoded.shape[1]].data.cpu().numpy()[:, 0].T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvRMIz86qL7U"
      },
      "source": [
        "with torch.no_grad():\n",
        "    audio = denoiser(waveglow.infer(mel_outputs_postnet, sigma=0.8), 0.01)[:, 0]\n",
        "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ6BeahWd3qD"
      },
      "source": [
        "### Only Pitch contour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgfJdwQH-xcw"
      },
      "source": [
        "* Seems to work on changed text, but not too well.\n",
        "* Styles can be changed by writing numbers in place of ```mel```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ8JLKQxeJmi"
      },
      "source": [
        "peaker_id = torch.LongTensor([0]).cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "    mel_outputs, mel_outputs_postnet, gate_outputs, alignments = mellotron.inference(\n",
        "        (text_encoded, mel, speaker_id, pitch_contour))\n",
        "\n",
        "plot_mel_f0_alignment(x[2].data.cpu().numpy()[0],\n",
        "                      mel_outputs_postnet.data.cpu().numpy()[0],\n",
        "                      pitch_contour.data.cpu().numpy()[0, 0],\n",
        "                      alignments.data.cpu().numpy()[0].T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnDXGXjPedUe"
      },
      "source": [
        "with torch.no_grad():\n",
        "    audio = denoiser(waveglow.infer(mel_outputs_postnet, sigma=0.8), 0.01)[:, 0]\n",
        "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}